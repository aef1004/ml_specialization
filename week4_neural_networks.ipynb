{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5fb5e0c-1e86-4b5f-bc44-c77b2c904115",
   "metadata": {},
   "source": [
    "# Week 4: Neural networks Intuition\n",
    "\n",
    "- neural networks intuition\n",
    "- demand prediction\n",
    "- tensorflow\n",
    "- neural network implementation \"by hand\"\n",
    "- vectorization\n",
    "\n",
    "AI (two main subsets)\n",
    " - ANI - artificial narrow intelligence (e.g., self driving car, web search) - there has been a lot of improvement in this field recently\n",
    " - AGI - artificial general intelligence (e.g., doing anything a human can do)\n",
    "\n",
    "**Questions**\n",
    " - how do you choose the # of layers and # of units for each layer in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1661a24b-fca0-4a6e-b419-4db9c5208ae1",
   "metadata": {},
   "source": [
    "### Optional Lab: Neurons and Layers\n",
    "Note I cannot download tensorflow now because I have python 3.13 but tensorflow only works on up to 3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42982bd-f516-4c85-8803-8179edf02a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from lab_utils_common import dlc\n",
    "from lab_neurons_utils import plt_prob_1d, sigmoidnp, plt_linear, plt_logistic\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52622b-9ded-4dac-9d00-bcb8ef92951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)           #(size in 1000 square feet)\n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32)       #(price in 1000s of dollars)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(X_train, Y_train, marker='x', c='r', label=\"Data Points\")\n",
    "ax.legend( fontsize='xx-large')\n",
    "ax.set_ylabel('Price (in 1000s of dollars)', fontsize='xx-large')\n",
    "ax.set_xlabel('Size (1000 sqft)', fontsize='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4585b-dce4-45f4-9d05-da39a897a4b3",
   "metadata": {},
   "source": [
    "Regression/Linear model\n",
    "Define a layer with one neuron or unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10733104-3bfb-4dff-952a-13c301321692",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = tf.keras.layers.Dense(units=1, activation = 'linear', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf390c86-0918-4e52-8310-00d00b27475f",
   "metadata": {},
   "source": [
    "We can see that the tensorflow linear_layer function has the same output as our dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62759b0b-0bbf-4601-8828-78511ba921c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = linear_layer(X_train[0].reshape(1,1))\n",
    "print(a1)\n",
    "\n",
    "\n",
    "# set some initial weight values \n",
    "set_w = np.array([[200]])\n",
    "set_b = np.array([100])\n",
    "\n",
    "# dot product\n",
    "alin = np.dot(set_w,X_train[0].reshape(1,1)) + set_b\n",
    "print(alin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a874cb-4825-4215-a982-0648dccd3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tf = linear_layer(X_train)\n",
    "prediction_np = np.dot( X_train, set_w) + set_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6698c00-e205-4e2f-b24a-b9dc07024059",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_linear(X_train, Y_train, prediction_tf, prediction_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc7e48-072c-41f2-8011-f783399a47bd",
   "metadata": {},
   "source": [
    "Neuron with Sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d53f8-d462-4ab6-9cf7-d128a29265ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1,1)  # 2-D Matrix\n",
    "Y_train = np.array([0,  0, 0, 1, 1, 1], dtype=np.float32).reshape(-1,1)  # 2-D Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683c289-bc7d-40e1-8fb9-c03e274853ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = Y_train == 1\n",
    "neg = Y_train == 0\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "ax.scatter(X_train[pos], Y_train[pos], marker='x', s=80, c = 'red', label=\"y=1\")\n",
    "ax.scatter(X_train[neg], Y_train[neg], marker='o', s=100, label=\"y=0\", facecolors='none', \n",
    "              edgecolors=dlc[\"dlblue\"],lw=3)\n",
    "\n",
    "ax.set_ylim(-0.08,1.1)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_title('one variable plot')\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054e7aa-54ff-4b9e-b1f1-386caa78cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1, input_dim=1,  activation = 'sigmoid', name='L1')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8509fe-0b69-46f4-ba4c-0db46ade0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf080b-5494-44c0-9c4c-c7d6adaa8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[2]])\n",
    "set_b = np.array([-4.5])\n",
    "# set_weights takes a list of numpy arrays\n",
    "logistic_layer.set_weights([set_w, set_b])\n",
    "print(logistic_layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c437a-c3f3-4839-9158-aa05fe15c7f8",
   "metadata": {},
   "source": [
    "See the sigmoid dot product is the same as the tensorflow prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51dc2e-670e-4070-82b6-fc481d06f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = model.predict(X_train[0].reshape(1,1))\n",
    "print(a1)\n",
    "alog = sigmoidnp(np.dot(set_w,X_train[0].reshape(1,1)) + set_b)\n",
    "print(alog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac75317-cc8d-49c0-939f-6e7ef5842f04",
   "metadata": {},
   "source": [
    "## Optional Lab: Coffee Roasting in TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c42c91-4288-47f2-98a4-1e5b1a8eb4b9",
   "metadata": {},
   "source": [
    "Additional notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6309b47c-6703-4406-8d0f-254f23a9a25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inner brackets are the rows\n",
    "# so this is 2 rows x 3 columns\n",
    "x = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "\n",
    "# this is what's used by tensor flow\n",
    "x = np.array([[200, 17]]) # 1 row x 2 columns\n",
    "\n",
    "x = np.array([[200],\n",
    "              [17]]) # 2 x 1\n",
    "\n",
    "# this is what's used for linear regression\n",
    "x = np.array([200, 17]) # 1D array - no rows or columns             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1668a94d-bd3f-462c-811d-3ea71c2a0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 'sequential' to string together different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747547f6-9c56-426b-af2f-03ef05075470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from lab_utils_common import dlc\n",
    "from lab_coffee_utils import load_coffee_data, plt_roast, plt_prob, plt_layer, plt_network, plt_output_unit\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688f6c9-6611-4190-8d94-af6823d0b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = load_coffee_data();\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db997a49-7c62-4f7d-b170-3103a5043d6b",
   "metadata": {},
   "source": [
    "We need to normalize the data - both before and if we input any future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f535212c-74e4-470a-9fb7-32906159debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Temperature Max, Min pre normalization: {np.max(X[:,0]):0.2f}, {np.min(X[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min pre normalization: {np.max(X[:,1]):0.2f}, {np.min(X[:,1]):0.2f}\")\n",
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)  # learns mean, variance\n",
    "Xn = norm_l(X)\n",
    "print(f\"Temperature Max, Min post normalization: {np.max(Xn[:,0]):0.2f}, {np.min(Xn[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min post normalization: {np.max(Xn[:,1]):0.2f}, {np.min(Xn[:,1]):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ccc30-e25f-4bc4-8384-f39e3f79a102",
   "metadata": {},
   "source": [
    "Tile/copy our data to increase the training set size and reduce the $ of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257ae6b-ff0e-4a06-9a13-f06dc9aaa6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.tile(Xn,(1000,1))\n",
    "Yt= np.tile(Y,(1000,1))   \n",
    "print(Xt.shape, Yt.shape)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3fd756-64bc-4ce6-9b56-5ad8638a431a",
   "metadata": {},
   "source": [
    "tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2570a200-4f43-4256-9664-356f0ab15d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(2,)),\n",
    "        Dense(3, activation='sigmoid', name = 'layer1'),\n",
    "        Dense(1, activation='sigmoid', name = 'layer2')\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74489c1-694a-4674-8c85-92d97de34ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc49749-c687-43c6-b4d6-bb55ab352f62",
   "metadata": {},
   "source": [
    "- The `model.compile` statement defines a loss function and specifies a compile optimization.\n",
    "- The `model.fit` statement runs gradient descent and fits the weights to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb28308-74ae-4b4d-9452-33ee31efeab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    Xt,Yt,            \n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06328d-bb68-4044-90b5-351e158eccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
    "print(\"W1:\\n\", W1, \"\\nb1:\", b1)\n",
    "print(\"W2:\\n\", W2, \"\\nb2:\", b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f80a9-83f9-4160-8cf9-375c625eb8f0",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a46bd-980d-4d27-b83a-ce1e2b64af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([\n",
    "    [200,13.9],  # positive example\n",
    "    [200,17]])   # negative example\n",
    "X_testn = norm_l(X_test)\n",
    "predictions = model.predict(X_testn)\n",
    "print(\"predictions = \\n\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db5d86-d4c3-43fa-9b93-3cd4bfe5b498",
   "metadata": {},
   "source": [
    "Convert the probabilities to a decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639cec5-0908-4c86-a690-63244cf340cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67daa35-911e-4bd4-a29a-ac77efe91463",
   "metadata": {},
   "source": [
    "## Optional Lab: Neural Network Implementation by Hand\n",
    "\n",
    "**Uses the data and normalization from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5df51-9cb8-47e2-8af2-c005ceeed8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the activation function\n",
    "# sigmoid is already implemented in the lab_utils_common.py file\n",
    "g = sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed7d35-1141-46b3-83af-d8198e717ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes activations of a dense layer\n",
    "def my_dense(a_in, W, b):\n",
    "    \"\"\"\n",
    "    Computes dense layer\n",
    "    Args:\n",
    "      a_in (ndarray (n, )) : Data, 1 example \n",
    "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
    "      b    (ndarray (j, )) : bias vector, j units  \n",
    "    Returns\n",
    "      a_out (ndarray (j,))  : j units|\n",
    "    \"\"\"\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for j in range(units):               \n",
    "        w = W[:,j]                                    \n",
    "        z = np.dot(w, a_in) + b[j]         \n",
    "        a_out[j] = g(z)               \n",
    "    return(a_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d0e75-fe12-4722-9638-85ce41c896cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sequential(x, W1, b1, W2, b2):\n",
    "    a1 = my_dense(x,  W1, b1)\n",
    "    a2 = my_dense(a1, W2, b2)\n",
    "    return(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4951568-59ed-49b9-b4fa-bc529325eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(X, W1, b1, W2, b2):\n",
    "    m = X.shape[0]\n",
    "    p = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        p[i,0] = my_sequential(X[i], W1, b1, W2, b2)\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d251214a-a14b-4ed2-ad30-7291fc96f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]])   # negative example\n",
    "X_tstn = norm_l(X_tst)  # remember to normalize\n",
    "predictions = my_predict(X_tstn, W1_tmp, b1_tmp, W2_tmp, b2_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64758784-e1dd-43fa-8083-9ede4b00d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e214e8-b811-46b9-b34d-fb79f54c39de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
